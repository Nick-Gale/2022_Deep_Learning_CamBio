{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3daa474e",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Deep Learning is a subset of learning of Machine Learning which itself may be considered a subset of Statistics. In its essence Deep Learning aims to achieve matching between two statistical distributions through a powerful graphical structure: the *neural network*. The deep in Deep Learning refers to the number of layers in the graph, and this will become clearer as we proceed through the course, but has to come to more generally imply the size of the models being used.\n",
    "\n",
    "This course will address several topics: we will cover the basic theory and history of neural networks; the primitive structures and functions found in a neural network; how to train a neural network; key methods of optimising training; different computational frameworks to work in; and several modern network topologies and the situations where they are best used. These topics will be addressed through the lecture notes and a series of workbooks which can be worked through:\n",
    "\n",
    "1. Introduction and Basics\n",
    "2. Hopfield Networks, and Multi-Layer Perceptrons\n",
    "3. Gradient descent, accelerated descent, and regularisation.\n",
    "4. Flux: Deep Learning in Julia\n",
    "5. PyTorch, Keras, and Tensor Flow: Deep Learning in Python\n",
    "6. Recurrent Neural Networks\n",
    "7. Convolutional Neural Networks\n",
    "8. Variational Autoencoders\n",
    "9. Generative Adversial Networks\n",
    "10. Transformer Networks\n",
    "11. Graph Neural Networks and beyond...\n",
    "\n",
    "This notebook will cover the basics: the biology, some of the basic building blocks, some essential terms and concepts, and some history. By the end of the notebook we should understand what a neuron is and why collections of model neurons may be able to peform learning tasks. We will code our own learning neuron: the perceptron.\n",
    "## 1.0 Some Biology\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21c07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df6b6a5",
   "metadata": {},
   "source": [
    "## 2.0 Mathematical Concepts\n",
    "\n",
    "1. Classification\n",
    "2. Regression\n",
    "    * Linear Regression\n",
    "    * Weights and Biases\n",
    "3. Models\n",
    "4. Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebcb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff38323",
   "metadata": {},
   "source": [
    "## 3.0 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769bc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
