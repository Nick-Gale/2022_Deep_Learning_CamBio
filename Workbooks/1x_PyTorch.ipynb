{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c40964",
   "metadata": {},
   "source": [
    "# Deep Learning in Python: PyTorch and TensorFlow\n",
    "\n",
    "Python is the *de facto* Machine Learning (and by extension, Deep Learning) language thanks to its excellent packages (Numpy, TensorFlow, Keras, and PyTorch), ease of entry (many online tutorials and familiar feeling language), and large community. These all very desirable components to have in an actively developing field. We have covered most of the course in Julia: don't worry, the Python and Julia communities are very close knit. \n",
    "\n",
    "This ntoebook will give a flavour for how to operate in the major Pythonic APIs: PyTorch, Tensor Flow, and Keras. Migrating between APIs usually just amounts to syntactic sugar and implementation details; none of the concepts we have learnt so far (or will learn) change between the API. The language is not as important as the concept. We wil therefore just signpost the way into these APIs.\n",
    "\n",
    "## 1.0 PyTorch\n",
    "\n",
    "Let's start by importing PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a1fb15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pytorch as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64a593",
   "metadata": {},
   "source": [
    "In PyTorch we understand every neural network to be their own graphical *object*. To this object we use constructors to add layers and methods to the object. The neural network is then trained by calling training methods and the data can be examined or the object can be used as a model. Every neural network is an object of the class NN so we shall start by creating a NN object:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550086a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2026edf",
   "metadata": {},
   "source": [
    "Now that we have the neural network instantiated as an object we can begin to add to it. We shall recreate the very simple n-layered convolutional network that we used as the example in our introduction notebook. Lets start by adding the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff2f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b6dfc0",
   "metadata": {},
   "source": [
    "We now need to add the regularisiation steps. This is done by adding drop out layers and calling a no gradient method on these layers so that PyTorch doesn't try to differentiate through them: would it make sense to do that? This improves the stability of the network. Let's add these features now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70355b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d38a14b",
   "metadata": {},
   "source": [
    "Finally, we need to define the loss functions. We originally chose mean-squared error for our loss function but we will change it here to demonstrate how one might customise the loss. The loss function we want to examine is $$ L(x) = |y - f(x)|^4 + abs(y-f(x)). This is not a very standard loss function and we might not even get a substantial benefit by implementing it, but it is *valid* and unique. Let's add this to the NN object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7170a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36d0cabd",
   "metadata": {},
   "source": [
    "The final thing left to do is to import some data and train the network. This is done by [INSERT ROUTINE HERE]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac7901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ef55f9",
   "metadata": {},
   "source": [
    "PyTorch has some great tools for examining how the training is proceeding as well as examining the results of a fully trained model. These include [INSERT]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e394b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
